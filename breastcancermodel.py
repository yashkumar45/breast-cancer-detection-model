# -*- coding: utf-8 -*-
"""breastcancermodel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LEdeNqtc0O35vEemIfiuMkwuSHT-ExlS
"""

#Description : This programs detect breast cancer, based off of data

#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# load the data
from google.colab import files
uploaded = files.upload()
df = pd.read_csv('data.csv')
df.head(7)

#count of the number of empty values in each column

#count the number of rows and columns in thr datset
df.shape

df.isna().sum()

#drop the column with all the missing values
df = df.dropna(axis=1)

#get the count of the number of rows and columns
df.shape

#geta\ acount of number of malognant (m) or benign (b cells)
df['diagnosis'].value_counts()

#visulise the count
sns.countplot(df['diagnosis'],label='count')

#look at the datatypes to see which columns neeed to be encoded
df.dtypes

#encode the caterogorical data values
from sklearn.preprocessing import LabelEncoder
labelencoder_Y = LabelEncoder()
labelencoder_Y.fit_transform(df.iloc[:,1].values)
df.iloc[:,1].values

# create a pair plot
sns.pairplot(df.iloc[:,1:6])

sns.pairplot(df.iloc[:,1:5],hue='diagnosis')

#print the first five rows of the new data
df.head(5)

#get the corelation of the coluns
df.iloc[:,1:12].corr()

# visualize the correlation
sns.heatmap(df.iloc[:,1:12].corr())

#visualise the corerelation
plt.figure(figsize=(10,10))
sns.heatmap(df.iloc[:,1:12].corr(),annot=True, fmt='.0%')

# split the dataset intpo independent and dependent(Y) data sets
X = df.iloc[:,2:31].values
Y = df.iloc[:,1].values

# Split the datset into 75 percent raining and 25 percent testing
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.25, random_state = 0)

# scale the data(feature scaling)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test= sc.fit_transform(X_test)
X_train

# create a function for the model
def models(X_train,Y_train):
  #Logistic regression
  from sklearn.linear_model import LogisticRegression
  log = LogisticRegression(random_state=0)
  log.fit(X_train,Y_train)

  #Decisssion tree
  from sklearn.tree import DecisionTreeClassifier
  tree = DecisionTreeClassifier(criterion ='entropy', random_state=0)
  tree.fit(X_train,Y_train)

  #Random forest classifire
  from sklearn.ensemble import RandomForestClassifier
  forest = RandomForestClassifier(n_estimators = 10,criterion ='entropy',random_state=0)
  forest.fit(X_train, Y_train)

  #print the model accuracy on the training data
  print('[0]Logistic Regression Training Accuracy:',log.score(X_train,Y_train))
  print('[1]Decision tree classifier training Accuracy:',tree.score(X_train,Y_train))
  print('[2]Random forest classifier Training Accuracy:',forest.score(X_train,Y_train))

  return log,tree,forest

#getting all of the models
model = models(X_train, Y_train)

#test model accuracy on test dat on confusion matrix
from sklearn.metrics import confusion_matrix

for i in range( len(model) ):
  print('Model',i)
  cm = confusion_matrix(Y_test,model[0].predict(X_test))

  TP = cm[0][0]
  TN = cm[1][1]
  FN = cm[1][0]
  FP =  cm[0][1]
  print(cm)
  print('Testing Accuracy',(TP + TN)/(TP + TN + FN + FP))

# show another way to get the atrics
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score

for i in range( len(model) ):
  print('Model',i)
  print( classification_report(Y_test,model[i].predict(X_test)))
  print( accuracy_score(Y_test,model[i].predict(X_test)))

# print the prediction of Random forest classifiesr
pred = model[2].predict(X_test)
print(pred)
print()
print(Y_test)

